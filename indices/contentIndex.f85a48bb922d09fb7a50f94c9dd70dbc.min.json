{"/":{"title":"Connected Maths","content":"","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/Bayes-Theorem":{"title":"Bayes Theorem","content":"\n-   Bayes' theorem is used to describe the probability of an event based on the prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems increases with age, Bayes' theorem allows the risk to an individual of a known age to be addressed more accurately. Bayes' theorem states that,\n    \n    $$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n    \n    $$Underlying Truth = \\frac{Likelihood \\times Belief(Prior Probability)}{Evidence} $$\n    \n    -   where \\(A\\) and \\(B\\) are the events and \\(P(B) \\neq 0\\)\n    -   \\(P(A|B)\\) is a Conditional Probability; the probability of event \\(A\\) occurring given that \\(B\\) is true. This is also called Posterior Probability of \\(A\\) given \\(B\\).\n    -   \\(P(B|A)\\) is also a conditional probability; the probability of event \\(B\\) occurring given that \\(A\\) is true. It can also be interpreted as likelihood of \\(A\\) given fixed \\(B\\).\n    -   \\(P(A)\\) and \\(P(B)\\) are the probabilities of observing \\(A\\) and \\(B\\) respectively, without any given conditions; they are also known as marginal probabilities.\n-   Proof of Bayes' Theorem for discrete events.\n    \n    $$ P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)} \\text {, if } P(B) \\neq 0 $$\n    \n    where \\(P(A \\cap B)\\) is the probability of both \\(\\mathrm{A}\\) and \\(\\mathrm{B}\\) being true. Similarly,  \n    \n    $$ P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)} \\text {, if } P(A) \\neq 0, $$\n    \n    Solving for \\(P(A \\cap B)\\) and substituting into the above expression for \\(P(A \\mid B)\\) yields Bayes' theorem:  \n    \n    $$ P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}, \\text { if } P(B) \\neq 0 \\text {. } $$\n","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/Bayesian-Decision-Theory":{"title":"Bayesian Decision Theory","content":"-   It is a fundamental statistical approach to the problem of pattern classification. It predicts the outcome not only based on previous observations but also by taking into account the current situation. It uses [[notes/Bayes Theorem]] heavily.\n    \n    -   Bayes' theorem is used to describe the probability of an event based on the prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems increases with age, Bayes' theorem allows the risk to an individual of a known age to be addressed more accurately. Bayes' theorem states that,\n        \n        $$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n        \n        $$Underlying Truth = \\frac{Likelihood \\times Belief(Prior Probability)}{Evidence} $$\n        \n        -   where \\(A\\) and \\(B\\) are the events and \\(P(B) \\neq 0\\)\n        -   \\(P(A|B)\\) is a Conditional Probability; the probability of event \\(A\\) occurring given that \\(B\\) is true. This is also called Posterior Probability of \\(A\\) given \\(B\\).\n        -   \\(P(B|A)\\) is also a conditional probability; the probability of event \\(B\\) occurring given that \\(A\\) is true. It can also be interpreted as likelihood of \\(A\\) given fixed \\(B\\).\n        -   \\(P(A)\\) and \\(P(B)\\) are the probabilities of observing \\(A\\) and \\(B\\) respectively, without any given conditions; they are also known as marginal probabilities.\n    \n-   Working of Bayesian Decision Theory:\n    -   Let's say we have features from a vector \\(x \\in R^d\\). A finite set of \\(c\\) categories \\(w_1, w_2, ..., w_c\\). So using Bayes' rule,\n        \n        $$ P\\left(\\omega_j / \\mathbf{x}\\right)=\\frac{p\\left(\\mathbf{x} / \\omega_j\\right) P\\left(\\omega_j\\right)}{p(\\mathbf{x})} $$\n        \n        where \\(p(\\mathbf{x})=\\sum_{j=1}^c p\\left(\\mathbf{x} / \\omega_j\\right) P\\left(\\omega_j\\right)\\)  \n        \n    -   A finite set of \\(I\\) actions \\(\\alpha_1, \\alpha_{2, \\ldots}, \\alpha_I\\). A loss function \\(\\lambda\\left(\\alpha_i / \\omega_j\\right)\\). The cost associated with taking action \\(\\alpha_i\\) when the correct classification category is \\(\\omega_j\\)\n    -   Suppose we observe \\(x\\) and take action \\(\\alpha_i\\), and the cost associated with action \\(\\alpha_i\\) with \\(\\omega_j\\) being the correct category is \\(\\lambda (\\alpha_i / \\omega_j)\\).\n    -   The **conditional risk** (or **expected risk**) with taking action \\(\\alpha_i\\) is:\n        \n        $$R\\left(a_i / \\mathbf{x}\\right)=\\sum_{j=1}^c \\lambda\\left(a_i / \\omega_j\\right) P\\left(\\omega_j / \\mathbf{x}\\right)$$\n        \n    -   Suppose \\(\\alpha(x)\\) is a general decision rule that determines which action \\(\\alpha_1, \\alpha_2, ... , \\alpha_I\\) to take for every x; then the overall risk is defined as:\n        \n        $$ R=\\int R(a(\\mathbf{x}) / \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x} $$\n        \n    -   For each sample, the **Bayes Decision Rule** minimizes \\(R\\) by:\n        -   Computing \\(R(\\alpha_i / x)\\) for every \\(\\alpha_i\\) given an \\(x\\).\n        -   Choosing the action \\(\\alpha_i\\) with the minimum \\(R(\\alpha_i/x)\\).\n        -   The resulting minimum overall risk is called **Bayes Risk** and is the best performance that can be achieved:\n            \n            $$R^* = min(R)$$\n            \n-   Why is Bayes' Classifier is the best classifier?","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/Gaussian-Mixture-Models":{"title":"Gaussian Mixture Models","content":"\n- Gaussian Mixture Models or GMM is a part of [[notes/clustering]] algorithms which clusters the data in an unsupervised learning problem.  \n- One important characteristic of GMM is that it is a soft clustering method, unlike [[notes/K mean clustering]], which means that it will associate each point to multiple clusters with a certain probability.  \n- A Gaussian Mixture is a function comprised of several Gaussians, each identified by $k \\in {1, ...K}$ , where $K$ is the number of the clusters of our dataset.  \n- Each Gaussian $k$ in the mixture is comprised of the following parameters:  \n\t- A mean $\\mu$ that defines its centre.  \n\t- A covariance $\\Sigma$ that defines its width. This would be equivalent to the dimensions of an ellipsoid in a multivariate scenario.  \n\t- A mixing probability $\\pi$ that defines how big or small the Gaussian function will be.  \n-  \n- In general, the Gaussian density function is given by:  \n$$\\mathcal{N}(\\mathbf{x} \\mid \\mu, \\Sigma)=\\frac{1}{(2 \\pi)^{D / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\mu)^T \\Sigma^{-1}(\\mathbf{x}-\\mu)\\right)$$  \n  Here, $x$ represents data points, and $D$ is the number of dimensions of each data point. $\\mu$ and $\\Sigma$ are the mean and covariance, respectively.  \n    \n$$\\ln \\mathcal{N}(\\mathbf{x} \\mid \\mu, \\Sigma)=-\\frac{D}{2} \\ln 2 \\pi-\\frac{1}{2} \\ln \\Sigma-\\frac{1}{2}(\\mathbf{x}-\\mu)^T \\Sigma^{-1}(\\mathbf{x}-\\mu)$$ - If we differentiate the above equation with respect to the mean and covariance and then equate to zero, we will be able to find the optimal values for these parameters, and the solutions will correspond to the [[notes/Maximum Likelihood Estimate (MLE)]].  \n","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/Lagrange-Dual-Function":{"title":"Lagrange Dual Function","content":"-   Lagrangian: Define Lagrangian $(L: \\mathbb{R}^n \\times \\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R})$ as\n    \n    $$ L(x, \\lambda, \\nu)=f_0(x)+\\sum_{i=1}^m \\lambda_i f_i(x)+\\sum_{i=1}^p \\nu_i h_i(x), $$\n    \n    with dom $(L=\\mathcal{D} \\times \\mathbb{R}^m \\times \\mathbb{R}^p$). Here $(\\lambda_i, \\nu_i)$ are called Lagrange multipliers. Here $(\\lambda)$ and $(\\nu)$ are called dual variables or Lagrange multiplier vectors.  \n    \n-   Lagrange Dual Function: Define the Lagrange dual function $(g: \\mathbb{R}^m \\times \\mathbb{R}^\\rho \\rightarrow \\mathbb{R})$\n    \n    $$ g(\\lambda, \\nu)=\\inf _{x \\in \\mathcal{D}} L(x, \\lambda, \\nu)=\\inf _{x \\in \\mathcal{D}}\\left(f_0(x)+\\sum_{i=1}^m \\lambda_i f_i(x)+\\sum_{i=1}^p \\nu_i h_i(x)\\right) $$","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/Maximum-Likelihood-Estimate-MLE":{"title":"","content":"","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null},"/notes/cummulative-distributive-function":{"title":"Cummulative Distributive Function","content":"CDF (cummulative distribution function) of any probability density function can be found by using integrating it. It can be thought of area under the curve of PDF.\nThe formula for the CDF is given:\n$$D(x) = \\frac{1}{2}[1 + sgn(x - \\mu)(1 - e^{\\frac{-|x - \\mu|}{b}}$$\nHere $sgn$ is a sign function.","lastmodified":"2022-11-26T19:42:22.569247568Z","tags":null}}
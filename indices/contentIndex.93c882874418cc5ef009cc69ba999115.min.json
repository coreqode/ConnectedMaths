{"/":{"title":"Connected Maths","content":"\n\n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Bayes-Theorem":{"title":"Bayes Theorem","content":"\n-   Bayes' theorem is used to describe the probability of an event based on the prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems increases with age, Bayes' theorem allows the risk to an individual of a known age to be addressed more accurately. Bayes' theorem states that,\n    \n    $$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n    \n    $$Underlying Truth = \\frac{Likelihood \\times Belief(Prior Probability)}{Evidence} $$\n    \n    -   where \\(A\\) and \\(B\\) are the events and \\(P(B) \\neq 0\\)\n    -   \\(P(A|B)\\) is a Conditional Probability; the probability of event \\(A\\) occurring given that \\(B\\) is true. This is also called Posterior Probability of \\(A\\) given \\(B\\).\n    -   \\(P(B|A)\\) is also a conditional probability; the probability of event \\(B\\) occurring given that \\(A\\) is true. It can also be interpreted as likelihood of \\(A\\) given fixed \\(B\\).\n    -   \\(P(A)\\) and \\(P(B)\\) are the probabilities of observing \\(A\\) and \\(B\\) respectively, without any given conditions; they are also known as marginal probabilities.\n-   Proof of Bayes' Theorem for discrete events.\n    \n    $$ P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)} \\text {, if } P(B) \\neq 0 $$\n    \n    where \\(P(A \\cap B)\\) is the probability of both \\(\\mathrm{A}\\) and \\(\\mathrm{B}\\) being true. Similarly,  \n    \n    $$ P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)} \\text {, if } P(A) \\neq 0, $$\n    \n    Solving for \\(P(A \\cap B)\\) and substituting into the above expression for \\(P(A \\mid B)\\) yields Bayes' theorem:  \n    \n    $$ P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}, \\text { if } P(B) \\neq 0 \\text {. } $$\n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Bayesian-Decision-Theory":{"title":"Bayesian Decision Theory","content":"-   It is a fundamental statistical approach to the problem of pattern classification. It predicts the outcome not only based on previous observations but also by taking into account the current situation. It uses [[notes/Bayes Theorem]] heavily.\n    \n    -   Bayes' theorem is used to describe the probability of an event based on the prior knowledge of conditions that might be related to the event. For example, if the risk of developing health problems increases with age, Bayes' theorem allows the risk to an individual of a known age to be addressed more accurately. Bayes' theorem states that,\n        \n        $$P(A \\mid B)=\\frac{P(B \\mid A) P(A)}{P(B)}$$\n        \n        $$Underlying Truth = \\frac{Likelihood \\times Belief(Prior Probability)}{Evidence} $$\n        \n        -   where \\(A\\) and \\(B\\) are the events and \\(P(B) \\neq 0\\)\n        -   \\(P(A|B)\\) is a Conditional Probability; the probability of event \\(A\\) occurring given that \\(B\\) is true. This is also called Posterior Probability of \\(A\\) given \\(B\\).\n        -   \\(P(B|A)\\) is also a conditional probability; the probability of event \\(B\\) occurring given that \\(A\\) is true. It can also be interpreted as likelihood of \\(A\\) given fixed \\(B\\).\n        -   \\(P(A)\\) and \\(P(B)\\) are the probabilities of observing \\(A\\) and \\(B\\) respectively, without any given conditions; they are also known as marginal probabilities.\n    \n-   Working of Bayesian Decision Theory:\n    -   Let's say we have features from a vector \\(x \\in R^d\\). A finite set of \\(c\\) categories \\(w_1, w_2, ..., w_c\\). So using Bayes' rule,\n        \n        $$ P\\left(\\omega_j / \\mathbf{x}\\right)=\\frac{p\\left(\\mathbf{x} / \\omega_j\\right) P\\left(\\omega_j\\right)}{p(\\mathbf{x})} $$\n        \n        where \\(p(\\mathbf{x})=\\sum_{j=1}^c p\\left(\\mathbf{x} / \\omega_j\\right) P\\left(\\omega_j\\right)\\)  \n        \n    -   A finite set of \\(I\\) actions \\(\\alpha_1, \\alpha_{2, \\ldots}, \\alpha_I\\). A loss function \\(\\lambda\\left(\\alpha_i / \\omega_j\\right)\\). The cost associated with taking action \\(\\alpha_i\\) when the correct classification category is \\(\\omega_j\\)\n    -   Suppose we observe \\(x\\) and take action \\(\\alpha_i\\), and the cost associated with action \\(\\alpha_i\\) with \\(\\omega_j\\) being the correct category is \\(\\lambda (\\alpha_i / \\omega_j)\\).\n    -   The **conditional risk** (or **expected risk**) with taking action \\(\\alpha_i\\) is:\n        \n        $$R\\left(a_i / \\mathbf{x}\\right)=\\sum_{j=1}^c \\lambda\\left(a_i / \\omega_j\\right) P\\left(\\omega_j / \\mathbf{x}\\right)$$\n        \n    -   Suppose \\(\\alpha(x)\\) is a general decision rule that determines which action \\(\\alpha_1, \\alpha_2, ... , \\alpha_I\\) to take for every x; then the overall risk is defined as:\n        \n        $$ R=\\int R(a(\\mathbf{x}) / \\mathbf{x}) p(\\mathbf{x}) d \\mathbf{x} $$\n        \n    -   For each sample, the **Bayes Decision Rule** minimizes \\(R\\) by:\n        -   Computing \\(R(\\alpha_i / x)\\) for every \\(\\alpha_i\\) given an \\(x\\).\n        -   Choosing the action \\(\\alpha_i\\) with the minimum \\(R(\\alpha_i/x)\\).\n        -   The resulting minimum overall risk is called **Bayes Risk** and is the best performance that can be achieved:\n            \n            $$R^* = min(R)$$\n            \n-   Why is Bayes' Classifier is the best classifier?","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Calculus":{"title":"Calculus","content":"This page contains topics related to Calculus.\n- [[notes/Lagrange Dual Function]]\n- [[notes/Taylor Series]]","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Correlation":{"title":"Correlation","content":"\n- Used to calculate the strength of a relation of the data.\n- Correlation equals $\\pm1$ if we can draw a straight line through all the points.\n- $corr(x,y) = \\frac {cov(x,y)}{\\sqrt{\\sigma(x) \\sigma(y)}}$\n\tThe denominator makes sure that the data is between 0-1.\t\n\t\n\t","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Covariance":{"title":"Covariance","content":"\n- Covariance gives us the relation of how the two data points are related. The data points may be multidimensional. \n- Data may be related with positive or negative trend, or no trend at all.\n- Covariance only tells us if the data is positively or negatively related, but tells nothing about the strength of the relation. \n- They are sensitive to scaling.\n- $cov(x,y) = \\sum_{i=1}^n \\frac{(x_i-\\hat x) (y_i-\\hat y)}{n}$\n- **Covariance is an Inner Product in a vector space, more specifically the Quotient Space**.\n\n\n# Correlation\n- Used to calculate the strength of a relation of the data.\n- Correlation equals $\\pm1$ if we can draw a straight line through all the points.\n- $corr(x,y) = \\frac {cov(x,y)}{\\sqrt{\\sigma(x) \\sigma(y)}}$\n\tThe denominator makes sure that the data is between 0-1.\t\n\t\n\t\n# p-values\n- Used to test the null-hypothesis.","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Expectation-Maximization":{"title":"Expectation Maximization","content":"This algorithm is usually used to fit multiple Gaussian distributions over a given dataset. This can be considered as an extension of *k means model*, where the centres are described by Gaussian parameters instead of a mean in Euclidean space.\n\n##### Multivariate Gaussian Distribution:\n$\\mathcal{N}(x; \\mu,\\Sigma) = \\frac{1}{(2\\pi)^{d/2}}\\ |\\Sigma|^{-1/2}\\ e^{( -\\frac{1}{2} (x-\\mu)^T|\\Sigma|^{-1/2}(x-\\mu))}$\t\n\nGiven the data, we can calculate the **mean** as:\n\n$\\mu = \\frac{1}{m}\\sum_ix^{(i)}$\n\nand **variance**:\n\n$\\Sigma = \\frac{1}{m}\\sum_i  (x^{(i)}-\\mu)^T(x^{(i)}-\\mu)$\n\nExpectation algorithm is iteratively done in 2 steps:\n1. **Expectation step**:\n\tWe calculate the probability of each point belonging to a gaussian using above formula. The distribution with maximum probability value is chosen as parent distribution.\n2. **Maximization step**:\n\tFor each gaussian, $\\mu$ and $\\Sigma$ values are recalculated using the newly assigned datapoints.\n\nAnother interesting application of EM [[notes/Kalman Filter]]","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Gaussian-Mixture-Models":{"title":"Gaussian Mixture Models","content":"\n- Gaussian Mixture Models or GMM is a part of [[notes/clustering]] algorithms which clusters the data in an unsupervised learning problem.  \n- One important characteristic of GMM is that it is a soft clustering method, unlike [[notes/K mean clustering]], which means that it will associate each point to multiple clusters with a certain probability.  \n- A Gaussian Mixture is a function comprised of several Gaussians, each identified by $k \\in {1, ...K}$ , where $K$ is the number of the clusters of our dataset.  \n- Each Gaussian $k$ in the mixture is comprised of the following parameters:  \n\t- A mean $\\mu$ that defines its centre.  \n\t- A covariance $\\Sigma$ that defines its width. This would be equivalent to the dimensions of an ellipsoid in a multivariate scenario.  \n\t- A mixing probability $\\pi$ that defines how big or small the Gaussian function will be.  \n-  \n- In general, the Gaussian density function is given by:  \n$$\\mathcal{N}(\\mathbf{x} \\mid \\mu, \\Sigma)=\\frac{1}{(2 \\pi)^{D / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(\\mathbf{x}-\\mu)^T \\Sigma^{-1}(\\mathbf{x}-\\mu)\\right)$$  \n  Here, $x$ represents data points, and $D$ is the number of dimensions of each data point. $\\mu$ and $\\Sigma$ are the mean and covariance, respectively.  \n    \n$$\\ln \\mathcal{N}(\\mathbf{x} \\mid \\mu, \\Sigma)=-\\frac{D}{2} \\ln 2 \\pi-\\frac{1}{2} \\ln \\Sigma-\\frac{1}{2}(\\mathbf{x}-\\mu)^T \\Sigma^{-1}(\\mathbf{x}-\\mu)$$ - If we differentiate the above equation with respect to the mean and covariance and then equate to zero, we will be able to find the optimal values for these parameters, and the solutions will correspond to the [[notes/Maximum Likelihood Estimate (MLE)]].  \n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Groups":{"title":"Groups","content":"This page contains topics related to Groups.\n- [[notes/Quaternions]]","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Heat-Equation":{"title":"Heat Equation","content":"Heat equation aims to model the distribution of heat over a surface with time. For 3 dimension, it is given as:\n\t\t   $\\frac{\\partial T}{\\partial t} = \\alpha(\\frac{\\partial^2 T}{\\partial x^2}+\\frac{\\partial^2 T}{\\partial y^2}+\\frac{\\partial^2 T}{\\partial z^2})$ = $\\alpha \\nabla^2T$ \nThe right hand side is the [[Laplacian]] operator. It states that the change in temperature at a give point $u$ is linearly dependent on the second derivative of the the temperature at that point, with respect to the space ( shape ). Here $\\alpha$ is the thermal *diffusivity* of the medium. \n\n\n- It is closely related to spectral geometry.\n\nSolving heat equation would mean finding the temperature at any given point of the domain at time any time *t*.\nA function in the domain that satisfies the equation:\n$u_t = \\alpha \\nabla^2 u= \\alpha \\Delta u$\n(i.e second derivative of the function in the domain is equal to the function itself) is the solution to the heat equation.\n\nIntuitively, heat diffusion at a point of surface depends on the curvature of the heat  diffusion function itself. If the function is convex, the temperature would decrease at that point, in time and visa versa. Meaning, the change in temperature at any point depends on the gradient of the temperature.\n\n\nIn equilibrium, $u_t=0$ to solve the heat equation, we solve the Laplace equation: $\\nabla ^ 2 u=0$. \n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Kalman-Filter":{"title":"Kalman Filter","content":"\n**Kalman filter** is used recursive estimation of system state. It has two steps:\n- Prediction \n- Estimation\n\nIt makes the following assumption:\n- The world is Gaussian.\n- All models are linear.\n\n\n#### Kalman Filter:\nIt takes a mean of prediction and observation from, say, sensor to estimate it's current state.  It's a weighted  mean between the two. Assume the linear model function:\n$$ f(x) = Ax+B $$\nThen we have our prediction:\n$$ x_t = A_t x_{t-1} + B_t u_t + \\epsilon_t $$\nAnd our observation:\n$$ z_t = C_tx_t + \\delta_t $$\n\nThe matrix $A_t$ tells us how the state evolved without any controls or errors. $B_t$ tells how the state changes with control commands $u_t$. $C_t$ tells us how to map the state $x_t$ to an observation. $\\epsilon_t$ and $\\delta_t$ are Gaussian noise in the system.\n\nWe model the probability distribution for the observation and the prediction. This system makes sure that everything stays Gaussian. We have the **Kalman Filter Algorithm** as:\n\n1. $Kalman\\_filter(\\mu_{t-1},\\Sigma_{t-1},u_t,z_t)$:\n2. $\\tilde\\mu_t = A_t \\mu_{t-1} + B_t u_t$             \n3.  $\\tilde\\Sigma_t = A_t \\Sigma_{t-1} A_t^T+ R_t$\n4.  $K_t = \\tilde\\Sigma_t C^T_t(C_t \\tilde\\Sigma_t C^T_t  + Q_t)^{-1}$\n5.  $\\mu_t = \\mu_{t-1} + K_t(z_t - C_t \\tilde\\mu_t)$\n6.  $\\Sigma_t = (I - K_t C_t) \\tilde\\Sigma_t$\n7. return $\\mu_t,\\Sigma_t$\n\n#### Extended Kalman Filter\nIf we are in a Gaussian Linear system, then Kalman filter is Optimal. Otherwise we use Extended Kalman Filter.\tIt performs local linearization via Taylor series. \n\nFor cases when the systems are not linear, the functions change to:\n$$ x_t = g(u_t, x_{t-1}) + \\epsilon_t $$ \n$$ z_t = h(x_t) + \\delta_t $$\n\n\nWe use  **Extended Kalman Filter** as:\n1. $Extended\\_Kalman\\_filter(\\mu_{t-1},\\Sigma_{t-1},u_t,z_t)$:\n2. $\\tilde\\mu_t = g(u_t, \\mu_{t-1} )$             \n3.  $\\tilde\\Sigma_t = G_t \\Sigma_{t-1} G_t^T+ R_t$\n4.  $K_t = \\tilde\\Sigma_t H^T_t(H_t \\tilde\\Sigma_t H^T_t  + Q_t)^{-1}$\n5.  $\\mu_t = \\mu_{t-1} + K_t(z_t - h(\\mu_t))$\n6.  $\\Sigma_t = (I - K_t H_t) \\tilde\\Sigma_t$\n7. return $\\mu_t,\\Sigma_t$\n\n##### Working of system:\n- If the noise in the sensor is zero, the state space is directly mapped to observation without considering the prediction.\n- If the noise is maximum, then the state space is calculated using only the prediction, since the observation is too noisy.","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Lagrange-Dual-Function":{"title":"Lagrange Dual Function","content":"-   Lagrangian: Define Lagrangian $(L: \\mathbb{R}^n \\times \\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R})$ as\n    \n    $$ L(x, \\lambda, \\nu)=f_0(x)+\\sum_{i=1}^m \\lambda_i f_i(x)+\\sum_{i=1}^p \\nu_i h_i(x), $$\n    \n    with dom $(L=\\mathcal{D} \\times \\mathbb{R}^m \\times \\mathbb{R}^p$). Here $(\\lambda_i, \\nu_i)$ are called Lagrange multipliers. Here $(\\lambda)$ and $(\\nu)$ are called dual variables or Lagrange multiplier vectors.  \n    \n-   Lagrange Dual Function: Define the Lagrange dual function $(g: \\mathbb{R}^m \\times \\mathbb{R}^\\rho \\rightarrow \\mathbb{R})$\n    \n    $$ g(\\lambda, \\nu)=\\inf _{x \\in \\mathcal{D}} L(x, \\lambda, \\nu)=\\inf _{x \\in \\mathcal{D}}\\left(f_0(x)+\\sum_{i=1}^m \\lambda_i f_i(x)+\\sum_{i=1}^p \\nu_i h_i(x)\\right) $$","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Laplace-Beltrami":{"title":"Laplace-Beltrami Operator","content":"Laplace Beltrami operator ($\\Delta$) takes a function and gives out another function. It is the generalisation of Euclidean [[Laplacian]] Operator on manifolds. Laplacian eigenfunctions depend on each shape and thus \n coefficients or learned filters from one shape are not trivially transferable to another.\n\n###### Properties of LB operator\n- Invariant under [[Isometric deformation]].\n- Has countable eigen decomposition\n\t\t\t$\\Delta \\phi_i = \\lambda_i\\phi_i$    that forms orthonormal basis for $L^2(\\mathcal{M})$\n- Characterises geodesic distance.\n\n ###### Eigen functions\n Eigen functions on the LB of a shape ( or manifold $\\mathcal{M}$) has desirable properties. Any function on $\\mathcal{M}$ can be expressed as a linear sum of the eigen functions on the LB  of $\\mathcal{M}$. The basis function can be given as\n $f = \\sum^\\inf_0 c_i \\phi_i = \\sum^\\inf_0\u003cf_i, \\phi_i\u003e\\phi_i =  \\sum^k_0\u003cf_i, \\phi_i\u003e\\phi_i$ \n\nIt is very similar to Fourier transforms.\n\n**NOTE**: Eigenfunctions of Laplace-Beltrami operator on a sphere correspond to basis function of spherical harmonics.\n\n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Probabilistic-Modelling":{"title":"Probabilistic Modelling","content":"This page contains topics related to Probabilistic Modelling.\n[[notes/Bayes Theorem]]\n[[notes/Bayesian Decision Theory]]\n[[notes/Covariance]]\n[[notes/Correlation]]\n[[notes/cummulative distributive function]]\n[[notes/Expectation Maximization]]\n[[notes/Gaussian Mixture Models]]","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Quaternions":{"title":"Quaternions","content":"These are described similar to complex numbers. They can be imagined as existing in 4D space. They are composed of 1D real number line (real part) and 3 imaginary complex number lines (vector part). They can be represented as:\n$a + bi + cj + dk$\nwhere $a,b,c,d \\in \\mathbb{R}$ and $i,j,k$ are imaginary/ quaternion units. \n\nThis [video](https://www.youtube.com/watch?v=d4EgbgTm0Bg\u0026ab_channel=3Blue1Brown) gives a good way to visualise this 4D space.\n\n#### Multiplication rules:\n- $i^2 = j^2 = k^2 = -1$\n- $ij = -ji = k$\n- $jk = -kj = i$\n- $ki = -ik = j$\n\n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/Taylor-Series":{"title":"Taylor Series","content":"The Taylor series of a real or complex-valued function _f_ (_x_) that is infinitely differentiable at a real or complex number *a* is the power series.\n\n${\\displaystyle f(a)+{\\frac {f'(a)}{1!}}(x-a)+{\\frac {f''(a)}{2!}}(x-a)^{2}+{\\frac {f'''(a)}{3!}}(x-a)^{3}+\\cdots }$\n\nwhere _n_! denotes the factorial of n. In the more compact sigma notation, this can be written as\n\n${\\displaystyle \\sum _{n=0}^{\\infty }{\\frac {f^{(n)}(a)}{n!}}(x-a)^{n}}!$\n\nwhere _f_(_n_)(_a_) denotes the nth derivative of *f* evaluated at point *a*.\n","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null},"/notes/cummulative-distributive-function":{"title":"Cummulative Distributive Function","content":"CDF (cummulative distribution function) of any probability density function can be found by using integrating it. It can be thought of area under the curve of PDF.\nThe formula for the CDF is given:\n$$D(x) = \\frac{1}{2}[1 + sgn(x - \\mu)(1 - e^{\\frac{-|x - \\mu|}{b}}$$\nHere $sgn$ is a sign function.","lastmodified":"2022-11-28T09:26:55.960362232Z","tags":null}}